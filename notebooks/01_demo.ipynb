{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c1aee9",
   "metadata": {},
   "source": [
    "# In-class Demo: Importing Data\n",
    "\n",
    "This notebook demonstrates reading a variety of data sources into Python using Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1ee27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA = /Users/besee/Library/CloudStorage/OneDrive-Personal/Documents/STAT 386/importing-data-class/data/demo\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, json\n",
    "BASE = Path().resolve().parents[0] if (Path().resolve().name == \"notebooks\") else Path().resolve()\n",
    "DATA = BASE / \"data\" / \"demo\"\n",
    "print(\"DATA =\", DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5589cd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id               name major   gpa  grad_year\n",
      "0   1       Ada Lovelace    CS  3.90       1843\n",
      "1   2        Alan Turing  Math  3.80       1934\n",
      "2   3       Grace Hopper  EECS  3.95       1930\n",
      "3   4    Edsger Dijkstra  Math  3.70       1956\n",
      "4   5  Katherine Johnson  Math  3.92       1937\n",
      "id       int64\n",
      "name    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- CSV\n",
    "csv_path = DATA / \"csv\" / \"students.csv\"\n",
    "df_csv = pd.read_csv(csv_path)\n",
    "print(df_csv.head())\n",
    "# Common args: sep, header, index_col, nrows, encoding, usecols, dtype, compression\n",
    "df_subset = pd.read_csv(csv_path, usecols=[\"id\",\"name\"], dtype={\"id\":\"int64\"})\n",
    "print(df_subset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f896dd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  order_id        date product  quantity  price\n",
      "0     A001  2024-01-05  Widget         3  19.99\n",
      "1     A002  2024-01-06  Gadget         1  29.50\n",
      "2     A003  2024-01-06  Widget         2  19.99\n",
      "3     A004  2024-01-07  Doodad         5   3.75\n",
      "4     A005  2024-01-08  Widget         1  19.99\n"
     ]
    }
   ],
   "source": [
    "# --- TSV (tab-delimited)\n",
    "tsv_path = DATA / \"tsv\" / \"sales.tsv\"\n",
    "df_tsv = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "print(df_tsv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22564fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id               name major   gpa  grad_year\n",
      "0   1       Ada Lovelace    CS  3.90       1843\n",
      "1   2        Alan Turing  Math  3.80       1934\n",
      "2   3       Grace Hopper  EECS  3.95       1930\n",
      "3   4    Edsger Dijkstra  Math  3.70       1956\n",
      "4   5  Katherine Johnson  Math  3.92       1937\n"
     ]
    }
   ],
   "source": [
    "# --- Compressed CSV (gzip)\n",
    "gz_path = DATA / \"csv_gz\" / \"students.csv.gz\"\n",
    "df_gz = pd.read_csv(gz_path, compression=\"gzip\")\n",
    "print(df_gz.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e50c134",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'openpyxl' from 'pip' (/Users/besee/.virtualenvs/r-tensorflow/lib/python3.11/site-packages/pip/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Excel (may require 'openpyxl')\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpip\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m openpyxl\n\u001b[32m      3\u001b[39m excel_path = DATA / \u001b[33m\"\u001b[39m\u001b[33mexcel\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mgrades.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'openpyxl' from 'pip' (/Users/besee/.virtualenvs/r-tensorflow/lib/python3.11/site-packages/pip/__init__.py)"
     ]
    }
   ],
   "source": [
    "# --- Excel (may require 'openpyxl')\n",
    "from pip import openpyxl\n",
    "excel_path = DATA / \"excel\" / \"grades.xlsx\"\n",
    "try:\n",
    "    df_excel = pd.read_excel(excel_path)  # default: first sheet\n",
    "    print(df_excel.head())\n",
    "    all_sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "    print(\"Sheets:\", list(all_sheets))\n",
    "except Exception as e:\n",
    "    print(\"Excel read failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b3f2cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'John', 'age': 30, 'city': 'New York'}, {'name': 'Jane', 'age': 27, 'city': 'Chicago'}, {'name': 'Carlos', 'age': 35, 'city': 'Austin'}]\n",
      "[{'order_id': 'A100', 'customer': {'id': 1, 'name': 'Alice'}, 'items': [{'sku': 'WID-001', 'qty': 2, 'price': 9.99}, {'sku': 'GAD-010', 'qty': 1, 'price': 29.5}], 'shipping': {'city': 'Boston', 'state': 'MA'}}, {'order_id': 'A101', 'customer': {'id': 2, 'name': 'Bob'}, 'items': [{'sku': 'WID-001', 'qty': 1, 'price': 9.99}, {'sku': 'DD-404', 'qty': 5, 'price': 3.75}], 'shipping': {'city': 'Seattle', 'state': 'WA'}}]\n",
      "       sku  qty  price order_id customer.id customer.name\n",
      "0  WID-001    2   9.99     A100           1         Alice\n",
      "1  GAD-010    1  29.50     A100           1         Alice\n",
      "2  WID-001    1   9.99     A101           2           Bob\n",
      "3   DD-404    5   3.75     A101           2           Bob\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "# --- JSON (flat)\n",
    "people_path = DATA / \"json\" / \"people.json\"\n",
    "with open(people_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    people = json.load(f)\n",
    "print(people)\n",
    "\n",
    "# --- JSON (nested) with json_normalize\n",
    "nested_path = DATA / \"json\" / \"orders_nested.json\"\n",
    "with open(nested_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    orders = json.load(f)\n",
    "print(orders)\n",
    "\n",
    "flat = json_normalize(orders, record_path=\"items\", meta=[\"order_id\", [\"customer\",\"id\"], [\"customer\",\"name\"]])\n",
    "print(flat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61fcf112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If data be the food of thought, import on;', 'Give me excess of files, that, surfeiting,']\n",
      "line count: 4\n"
     ]
    }
   ],
   "source": [
    "# --- Plain text with context manager\n",
    "poem_path = DATA / \"text\" / \"poem.txt\"\n",
    "with open(poem_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "print(text.splitlines()[:2])  # first 2 lines\n",
    "with open(poem_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(\"line count:\", len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40b3ec71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'lxml'.  Use pip or conda to install lxml.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/r-tensorflow/lib/python3.11/site-packages/pandas/compat/_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/lib/python3.11/importlib/__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1126\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:241\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1140\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'lxml'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- HTML tables (requires lxml)\u001b[39;00m\n\u001b[32m      2\u001b[39m html_path = DATA / \u001b[33m\"\u001b[39m\u001b[33mhtml\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mtables.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m tables = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhtml_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# returns a list of DataFrames\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumber of tables:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tables))\n\u001b[32m      5\u001b[39m tables[\u001b[32m0\u001b[39m].head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/r-tensorflow/lib/python3.11/site-packages/pandas/io/html.py:1240\u001b[39m, in \u001b[36mread_html\u001b[39m\u001b[34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1225\u001b[39m     [\n\u001b[32m   1226\u001b[39m         is_file_like(io),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1230\u001b[39m     ]\n\u001b[32m   1231\u001b[39m ):\n\u001b[32m   1232\u001b[39m     warnings.warn(\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal html to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_html\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/r-tensorflow/lib/python3.11/site-packages/pandas/io/html.py:971\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[39m\n\u001b[32m    969\u001b[39m retained = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m flav \u001b[38;5;129;01min\u001b[39;00m flavor:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     parser = \u001b[43m_parser_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflav\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m     p = parser(\n\u001b[32m    973\u001b[39m         io,\n\u001b[32m    974\u001b[39m         compiled_match,\n\u001b[32m   (...)\u001b[39m\u001b[32m    979\u001b[39m         storage_options,\n\u001b[32m    980\u001b[39m     )\n\u001b[32m    982\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/r-tensorflow/lib/python3.11/site-packages/pandas/io/html.py:918\u001b[39m, in \u001b[36m_parser_dispatch\u001b[39m\u001b[34m(flavor)\u001b[39m\n\u001b[32m    916\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mbs4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlxml.etree\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _valid_parsers[flavor]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/r-tensorflow/lib/python3.11/site-packages/pandas/compat/_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'lxml'.  Use pip or conda to install lxml."
     ]
    }
   ],
   "source": [
    "# --- HTML tables (requires lxml)\n",
    "html_path = DATA / \"html\" / \"tables.html\"\n",
    "tables = pd.read_html(str(html_path))  # returns a list of DataFrames\n",
    "print(\"Number of tables:\", len(tables))\n",
    "tables[0].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r-tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
